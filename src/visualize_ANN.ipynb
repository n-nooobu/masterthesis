{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コンスタレーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "\n",
    "sys.path.append('../')\n",
    "from pyopt.util import save_pickle, load_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ANN定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_shaping(input_signal, signal, max_tap, tap):\n",
    "    \"\"\"\n",
    "    input_signal: 伝送前の信号\n",
    "    signal: 伝送後の信号\n",
    "    max_tap: 最大の同時入力シンボル数\n",
    "    tap: 同時入力シンボル数\n",
    "    \n",
    "    signal = [x_0, x_1, ... , x_(n-1)]\n",
    "      |\n",
    "      |\n",
    "      v\n",
    "    x = [[x_0, x_1, ... , x_tap-1],\n",
    "            [x_1, x_2, ..., x_tap],\n",
    "                   .\n",
    "                   .\n",
    "                   .\n",
    "            [x_(n-tap), x_(n-tap+1), ..., x(n-1)]]\n",
    "      |\n",
    "      |\n",
    "      v\n",
    "    x = [[i_0, q_0, i_1, q_1, ... , i_(tap-1), q_(tap-1)],\n",
    "            [i_1, q_1, i_2, q_2, ... , i_tap, q_tap],\n",
    "                   .\n",
    "                   .\n",
    "                   .\n",
    "            [i_(n-tap), q_(n-tap), i_(n-tap+1), q_(n-tap+1), ..., i_(n-1), q_(n-1)]] (batch, input_dim) input_dim = tap * 2\n",
    "    \n",
    "    y  (batch, output_dim) output_dim = 2\n",
    "    \"\"\"\n",
    "    \n",
    "    x = np.zeros((len(input_signal) - (max_tap - 1), tap * 2), dtype=float)\n",
    "    y = np.zeros((len(input_signal) - (max_tap - 1), 2), dtype=float)\n",
    "    for i, j in enumerate(np.arange(max_tap // 2, len(input_signal) - max_tap // 2)):\n",
    "        x[i, 0::2] = signal[j - tap // 2: j + tap // 2 + 1].real\n",
    "        x[i, 1::2] = signal[j - tap // 2: j + tap // 2 + 1].imag\n",
    "        y[i, 0] = input_signal[j].real\n",
    "        y[i, 1] = input_signal[j].imag\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, x, y, mean, std):\n",
    "        self.x, self.y, self.mean, self.std = x, y, mean, std\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "        \n",
    "        x = (x - self.mean) / self.std\n",
    "        y = (y - self.mean) / self.std\n",
    "        return torch.Tensor(x), torch.Tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_neuron):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_neuron)\n",
    "        self.fc2 = nn.Linear(hidden_neuron, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evm_score(y_pred, y_true):\n",
    "    tmp = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        tmp += ((y_pred[i][0] - y_true[i][0]) ** 2 + (y_pred[i][1] - y_true[i][1]) ** 2) / (y_true[i][0] ** 2 + y_true[i][1] ** 2)\n",
    "    evm = torch.sqrt(tmp / len(y_pred))\n",
    "    return evm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(device, model, dataloaders_dict, criterion, optimizer, epochs, epochs_section=None):\n",
    "    for epoch in range(epochs):\n",
    "        if epochs_section is not None:\n",
    "            epoch += epochs_section[0]\n",
    "            end_epoch = epochs_section[1]\n",
    "        else:\n",
    "            end_epoch = epochs\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for phase in dataloaders_dict.keys():\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            epoch_loss = 0.0\n",
    "            epoch_evms = 0.0\n",
    "            \n",
    "            for x, y in dataloaders_dict[phase]:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(x)\n",
    "                    loss = criterion(outputs, y)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                    epoch_loss += loss.item() * x.size(0)\n",
    "                    epoch_evms += (evm_score(outputs, y)) ** 2 * x.size(0)\n",
    "            \n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_evm = torch.sqrt(epoch_evms / len(dataloaders_dict[phase].dataset)) * 100\n",
    "            \n",
    "            duration = str(datetime.timedelta(seconds=time.time() - start_time))[:7]\n",
    "            print('{} | Epoch: {}/{} | {} Loss: {:.4} | EVM: {:.4}'.format(duration, epoch + 1, end_epoch, phase, epoch_loss, epoch_evm))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_val_data(N, image_number='0', signal_type='image'):\n",
    "    # t_condition 伝送条件\n",
    "    signal_type = 'image'\n",
    "    form = 'RZ16QAM'  # 変調方式\n",
    "    n = 32  # 1シンボルあたりのサンプリング数[/symbol]\n",
    "    equalize = False  # 各シンボル数を均等にするか\n",
    "    baudrate = 28  # ボーレート[GBaud]\n",
    "    PdBm = 1  # 平均入力光パワー[dBm]\n",
    "    Ledfa = 100  # EDFAスパン[km]\n",
    "    stepedfa = 30  # SSFMの繰り返し計算ステップ数\n",
    "    gamma = 1.4  # 非線形係数[/W/km]\n",
    "    D = 16  # 分散パラメータ[ps/nm/km]\n",
    "    Alpha = 0.16  # 伝送損失[dB/km]\n",
    "    NF = 4  # ASE雑音指数[dB]\n",
    "    Lmax = 500  # 伝送距離[km]\n",
    "    ase = True  # ASE雑音を考慮するか\n",
    "    if signal_type == 'prbs':\n",
    "        # N = 13  # PRBSの次数\n",
    "        itr = 1  # PRBSの繰り返し回数\n",
    "    elif signal_type == 'random':\n",
    "        seed = 1234  # 乱数シード\n",
    "        bit_num = 10000  # ビット長を指定\n",
    "    elif signal_type == 'image':\n",
    "        target_dir = 'train'\n",
    "        step = 10  # =10 ---> (768, 1024) ---> (76, 102)\n",
    "        image_number = '0'\n",
    "        ebtb = True  # 8B10Bを行うか\n",
    "\n",
    "    # prbs.csv or random.csv or image.csvの列指定に用いる文字列\n",
    "    t_condition = 'form==\"'+str(form)+'\"&n=='+str(n)+'&equalize=='+str(equalize)+'&baudrate=='+str(baudrate)+'&PdBm=='+str(PdBm)+'&Ledfa=='+str(Ledfa)+'&stepedfa=='+str(stepedfa)+'&\\\n",
    "                            gamma=='+str(gamma)+'&D=='+str(D)+'&Alpha=='+str(Alpha)+'&NF=='+str(NF)+'&ase=='+str(ase)\n",
    "    if signal_type == 'prbs':\n",
    "        condition = 'N=='+str(N)+'&itr=='+str(itr)\n",
    "    elif signal_type == 'random':\n",
    "        condition = 'seed=='+str(seed)+'&bit_num=='+str(bit_num)\n",
    "    elif signal_type == 'image':\n",
    "        condition = 'target_dir==\"'+target_dir+'\"&step=='+str(step)+'&image_number==\"'+image_number+'\"&ebtb=='+str(ebtb)\n",
    "\n",
    "    # prbs.csv or random.csv or image.csvをpandasで読み込む\n",
    "    t_df_dir = '../data/input/'\n",
    "    t_df = pd.read_csv(t_df_dir+signal_type+'.csv', index_col=0)\n",
    "\n",
    "    # prbs.csv or random.csv or image.csvにおいて、指定した伝送条件を見たす行を抜き出す\n",
    "    t_query = t_df.query(condition + '&' + t_condition)\n",
    "\n",
    "    # 伝送信号を入力データに整形する\n",
    "    sgnl = load_pickle(t_query.iloc[0]['data_path'])\n",
    "    lc = sgnl.linear_compensation(Lmax, sgnl.signal['x_' + str(Lmax)])\n",
    "    x, y = data_shaping(sgnl.signal['x_0'][n//2::n], lc[n//2::n], max_tap, tap)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Model読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available now: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu') # 'cuda' if torch.cuda.is_available() else \n",
    "print('Device available now:', device)\n",
    "\n",
    "# l_condition 学習条件\n",
    "tap = 1\n",
    "max_tap = 501\n",
    "batch_size = 100\n",
    "neuron = 300\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "# t_condition 伝送条件\n",
    "signal_type = 'image'\n",
    "form = 'RZ16QAM'  # 変調方式\n",
    "n = 32  # 1シンボルあたりのサンプリング数[/symbol]\n",
    "equalize = False  # 各シンボル数を均等にするか\n",
    "baudrate = 28  # ボーレート[GBaud]\n",
    "PdBm = 1  # 平均入力光パワー[dBm]\n",
    "Ledfa = 100  # EDFAスパン[km]\n",
    "stepedfa = 30  # SSFMの繰り返し計算ステップ数\n",
    "gamma = 1.4  # 非線形係数[/W/km]\n",
    "D = 16  # 分散パラメータ[ps/nm/km]\n",
    "Alpha = 0.16  # 伝送損失[dB/km]\n",
    "NF = 4  # ASE雑音指数[dB]\n",
    "Lmax = 500  # 伝送距離[km]\n",
    "ase = True  # ASE雑音を考慮するか\n",
    "if signal_type == 'prbs':\n",
    "    N = 13  # PRBSの次数\n",
    "    itr = 1  # PRBSの繰り返し回数\n",
    "elif signal_type == 'random':\n",
    "    seed = 1234  # 乱数シード\n",
    "    bit_num = 10000  # ビット長を指定\n",
    "elif signal_type == 'image':\n",
    "    target_dir = 'train'\n",
    "    step = 10  # =10 ---> (768, 1024) ---> (76, 102)\n",
    "    image_number = '0'\n",
    "    ebtb = True  # 8B10Bを行うか\n",
    "\n",
    "# ANN.csvの列指定に用いる文字列\n",
    "l_condition = 'tap=='+str(tap)+'&max_tap=='+str(max_tap)+'&batch_size=='+str(batch_size)+'&neuron=='+str(neuron)+'&learning_rate=='+str(lr)\n",
    "t_condition = 'form==\"'+str(form)+'\"&n=='+str(n)+'&equalize=='+str(equalize)+'&baudrate=='+str(baudrate)+'&PdBm=='+str(PdBm)+'&Ledfa=='+str(Ledfa)+'&stepedfa=='+str(stepedfa)+'&\\\n",
    "                        gamma=='+str(gamma)+'&D=='+str(D)+'&Alpha=='+str(Alpha)+'&NF=='+str(NF)+'&ase=='+str(ase)\n",
    "if signal_type == 'prbs':\n",
    "    condition = 'N=='+str(N)+'&itr=='+str(itr)\n",
    "elif signal_type == 'random':\n",
    "    condition = 'seed=='+str(seed)+'&bit_num=='+str(bit_num)\n",
    "elif signal_type == 'image':\n",
    "    condition = 'target_dir==\"'+target_dir+'\"&step=='+str(step)+'&image_number==\"'+image_number+'\"&ebtb=='+str(ebtb)\n",
    "\n",
    "# ANN.csvをpandasで読み込む\n",
    "l_df_dir = '../data/params/ANN.csv'\n",
    "l_df = pd.read_csv(l_df_dir, index_col=0)\n",
    "\n",
    "# ANN.csvにおいて、指定した条件を満たす行だけqueryとして抜き出す\n",
    "l_query = l_df.query(l_condition + '&' + condition + '&' + t_condition + '&Lmax=='+str(Lmax))\n",
    "\n",
    "if len(l_query) == 0 or l_query['epochs'].max() < epochs:\n",
    "    print('指定された条件の学習結果は存在しません')\n",
    "else:\n",
    "    index = l_query[l_query['epochs']==epochs].index\n",
    "    model = ANN(input_dim=tap*2, output_dim=2, hidden_neuron=neuron).to(device)\n",
    "    model.load_state_dict(torch.load(l_query['params_path'][index].values[0]))\n",
    "\n",
    "x, y = prepare_val_data(N=13, image_number=image_number, signal_type=signal_type)\n",
    "mean = np.mean(x)\n",
    "std = np.std(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = prepare_val_data(N=13, image_number='0', signal_type='prbs')\n",
    "dataset = Dataset(x=x, y=y, mean=mean, std=std)\n",
    "dataloader = data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "annc = model(dataset[:][0]).detach().numpy()\n",
    "annc = annc * std + mean\n",
    "annc = annc[:, 0] + annc[:, 1] * 1j\n",
    "y_complex = y[:, 0] + y[:, 1] * 1j\n",
    "\n",
    "symbol, inverse, counts = np.unique(y_complex, return_inverse=True, return_counts=True)\n",
    "\n",
    "lim = 110000\n",
    "cm = plt.get_cmap('rainbow', 16)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "for i in range(len(symbol)):\n",
    "    ax.plot(annc[y_complex == symbol[i]].real, annc[y_complex == symbol[i]].imag, '.', color=[cm(i)[0], cm(i)[1], cm(i)[2]])\n",
    "for i in range(len(symbol)):\n",
    "    ax.plot(y_complex[y_complex == symbol[i]].real, y_complex[y_complex == symbol[i]].imag, 'o', color=[cm(i)[0], cm(i)[1], cm(i)[2]])\n",
    "ax.set_title('constellation 100%linear+ANN comp.')\n",
    "ax.set_xlim(-lim, lim)\n",
    "ax.set_ylim(-lim, lim);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2    0, 1\n",
      "3    0, 1\n",
      "Name: image_number, dtype: object\n"
     ]
    }
   ],
   "source": [
    "l_df = pd.read_csv(l_df_dir, index_col=0)\n",
    "for i in range(len(l_df)):\n",
    "    t = l_df.iloc[i]['image_number']\n",
    "    t2 = ''\n",
    "    for j in range(1, len(t), 3):\n",
    "        if j == 1:\n",
    "            t2 = t2 + t[j]\n",
    "        else:\n",
    "            t2 = t2 + ', ' + t[j]\n",
    "        l_df['image_number'].loc[i] = t2\n",
    "print(l_df['image_number'])\n",
    "l_df.to_csv(l_df_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
