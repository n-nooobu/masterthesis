{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 複素ANNによる非線形歪補償\n",
    "複素数を入力とする3層ANNによる補償"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "\n",
    "sys.path.append('../')\n",
    "from pyopt.util import save_pickle, load_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 データの整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_shaping(input_signal, signal, max_tap, tap):\n",
    "    \"\"\"\n",
    "    input_signal: 伝送前の信号\n",
    "    signal: 伝送後の信号\n",
    "    max_tap: 最大の同時入力シンボル数\n",
    "    tap: 同時入力シンボル数\n",
    "    \n",
    "    signal = [x_0, x_1, ... , x_(n-1)]\n",
    "      |\n",
    "      |\n",
    "      v\n",
    "    x = [[x_0, x_1, ... , x_tap-1],\n",
    "            [x_1, x_2, ..., x_tap],\n",
    "                   .\n",
    "                   .\n",
    "                   .\n",
    "            [x_(n-tap), x_(n-tap+1), ..., x(n-1)]]\n",
    "      |\n",
    "      |\n",
    "      v\n",
    "    x = [[i_0, q_0, i_1, q_1, ... , i_(tap-1), q_(tap-1)],\n",
    "            [i_1, q_1, i_2, q_2, ... , i_tap, q_tap],\n",
    "                   .\n",
    "                   .\n",
    "                   .\n",
    "            [i_(n-tap), q_(n-tap), i_(n-tap+1), q_(n-tap+1), ..., i_(n-1), q_(n-1)]] (batch, input_dim) input_dim = tap * 2\n",
    "    \n",
    "    y  (batch, output_dim) output_dim = 2\n",
    "    \"\"\"\n",
    "    \n",
    "    x = np.zeros((len(input_signal) - (max_tap - 1), tap, 2), dtype=float)\n",
    "    y = np.zeros((len(input_signal) - (max_tap - 1), 2), dtype=float)\n",
    "    for i, j in enumerate(np.arange(max_tap // 2, len(input_signal) - max_tap // 2)):\n",
    "        x[i, :, 0] = signal[j - tap // 2: j + tap // 2 + 1].real\n",
    "        x[i, :, 1] = signal[j - tap // 2: j + tap // 2 + 1].imag\n",
    "        y[i, 0] = input_signal[j].real\n",
    "        y[i, 1] = input_signal[j].imag\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x size:  (1998, 29, 2)\n",
      "y size:  (1998, 2)\n",
      "[[ 51598.75641186 -53403.3657517 ]\n",
      " [-32145.84759244  96508.43591778]\n",
      " [-30606.37446336  95283.58932182]\n",
      " [ 32503.60952844  13910.52002391]\n",
      " [  8248.62335619  73391.81300168]\n",
      " [ 29107.6877347   14808.73597731]\n",
      " [-78280.98856905  15366.79259349]\n",
      " [-76605.44555413  12791.23534176]\n",
      " [ 69345.95709822  -8729.55171237]\n",
      " [ 36932.5922594   11156.38959978]\n",
      " [ 13056.01107017 -32846.73484666]\n",
      " [ 10610.89876389 -34963.38298674]\n",
      " [-73494.72750711   7190.0287674 ]\n",
      " [-49860.52436413  54128.52098679]\n",
      " [-53019.95429361  53670.26520552]\n",
      " [ 32274.63575034 -91081.39804461]\n",
      " [-14385.94066463  30341.90659466]\n",
      " [-47630.74129796  49235.95785073]\n",
      " [-11546.66807361 -75020.35362366]\n",
      " [-11274.86250656  31430.37354787]\n",
      " [-51761.20934421  52640.09062926]\n",
      " [-92079.7374958  -28400.06490156]\n",
      " [-54174.37271402  50576.41182636]\n",
      " [-67054.54768817  15313.41343857]\n",
      " [ 96034.7954907   33242.87671139]\n",
      " [ 50154.90489795 -49671.1420593 ]\n",
      " [-93925.54099544 -34256.15458994]\n",
      " [-30446.56620013 -13048.71261142]\n",
      " [  9693.42456563 -29001.58083495]]\n",
      "[-70474.95606832  23491.65202277]\n"
     ]
    }
   ],
   "source": [
    "#動作確認\n",
    "tap = 29\n",
    "max_tap = 51\n",
    "\n",
    "df_dir = '../data/input/prbs.csv'\n",
    "df = pd.read_csv(df_dir, index_col=0)  # dataframe読み込み\n",
    "condition = (df['N']==13) & (df['itr']==1) & (df['form']=='RZ16QAM') & (df['n']==32) & (df['equalize']==False) & (df['baudrate']==28) & (df['PdBm']==1)\n",
    "sgnl = load_pickle(df[condition].iloc[0]['data_path'])  # dataframeから条件と合う行を取得し,pickleの保存先(data_path)にアクセス\n",
    "lc = sgnl.linear_compensation(500, sgnl.signal['x_500'])\n",
    "x, y = data_shaping(sgnl.signal['x_0'][16::32], lc[16::32], max_tap, tap)  # ANNに入力できるようにデータを整形\n",
    "\n",
    "print('x size: ', x.shape)\n",
    "print('y size: ', y.shape)\n",
    "print(x[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 51598.7578-53403.3672j, -32145.8477+96508.4375j,\n",
      "         -30606.3750+95283.5859j,  ...,\n",
      "         -93925.5391-34256.1562j, -30446.5664-13048.7129j,\n",
      "           9693.4248-29001.5801j],\n",
      "        [-32145.8477+96508.4375j, -30606.3750+95283.5859j,\n",
      "          32503.6094+13910.5205j,  ...,\n",
      "         -30446.5664-13048.7129j,   9693.4248-29001.5801j,\n",
      "          53869.6953+53203.7969j],\n",
      "        [-30606.3750+95283.5859j,  32503.6094+13910.5205j,\n",
      "           8248.6230+73391.8125j,  ...,\n",
      "           9693.4248-29001.5801j,  53869.6953+53203.7969j,\n",
      "         -74834.9922+12591.7324j],\n",
      "        ...,\n",
      "        [-57464.2109-54496.4727j, -71785.1406+16135.0635j,\n",
      "         -37748.6445-11243.9277j,  ...,\n",
      "         -10821.5039-70501.7188j, -72369.8047+16814.8672j,\n",
      "         -10232.1523+33094.5391j],\n",
      "        [-71785.1406+16135.0635j, -37748.6445-11243.9277j,\n",
      "          96017.2891+27587.5176j,  ...,\n",
      "         -72369.8047+16814.8672j, -10232.1523+33094.5391j,\n",
      "         -12742.2695-76211.6172j],\n",
      "        [-37748.6445-11243.9277j,  96017.2891+27587.5176j,\n",
      "          29571.5430+13914.4229j,  ...,\n",
      "         -10232.1523+33094.5391j, -12742.2695-76211.6172j,\n",
      "          12861.2490-31992.7305j]])\n"
     ]
    }
   ],
   "source": [
    "x_tensor = torch.Tensor(x)\n",
    "x_complex = torch.view_as_complex(x_tensor)\n",
    "print(x_complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 平均,標準偏差の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  1153.2726078905946\n",
      "std:  52094.955682540436\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(x)\n",
    "std = np.std(x)\n",
    "\n",
    "print('mean: ', mean)\n",
    "print('std: ', std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, x, y, mean, std):\n",
    "        self.x, self.y, self.mean, self.std = x, y, mean, std\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "        \n",
    "        x = (x - self.mean) / self.std\n",
    "        y = (y - self.mean) / self.std\n",
    "        \n",
    "        x = torch.Tensor(x)\n",
    "        y = torch.Tensor(y)\n",
    "        \n",
    "        x_i = x[:, 0]\n",
    "        x_q = x[:, 1]\n",
    "        y_i = y[0]\n",
    "        y_q = y[1]\n",
    "        return x_i, x_q, y_i, y_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  -0.3059248\n",
      "std:  0.9654936\n",
      "tensor([ 0.9683, -0.6392, -0.6096,  0.6018,  0.1362,  0.5366, -1.5248, -1.4926,\n",
      "         1.3090,  0.6868,  0.2285,  0.1815, -1.4329, -0.9792, -1.0399,  0.5974,\n",
      "        -0.2983, -0.9364, -0.2438, -0.2386, -1.0157, -1.7897, -1.0621, -1.3093,\n",
      "         1.8213,  0.9406, -1.8251, -0.6066,  0.1639])\n",
      "tensor(-1.3750)\n"
     ]
    }
   ],
   "source": [
    "#動作確認\n",
    "train_dataset = Dataset(x=x, y=y, mean=mean, std=std)\n",
    "\n",
    "index = 0\n",
    "x_i, x_q, y_i, y_q = train_dataset.__getitem__(index)\n",
    "x_array = x_i.detach().numpy()\n",
    "\n",
    "print('mean: ', np.mean(x_array))\n",
    "print('std: ', np.std(x_array))\n",
    "print(x_i)\n",
    "print(y_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloaders_dict = {'train': train_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zrelu(x_i, x_q):\n",
    "    x_i, x_q = x_i.clone(), x_q.clone()\n",
    "    for i in range(x_i.shape[0]):\n",
    "        for j in range(x_i.shape[1]):\n",
    "            if x_i[i, j] < 0 or x_q[i, j] < 0:\n",
    "                x_i[i, j] = 0\n",
    "                x_q[i, j] = 0\n",
    "    return x_i, x_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crelu(x_i, x_q):\n",
    "    x_i, x_q = x_i.clone(), x_q.clone()\n",
    "    x_i, x_q = F.relu(x_i), F.relu(x_q)\n",
    "    return x_i, x_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        # 重み定義 Xavierの初期値\n",
    "        k = 1 / in_features\n",
    "        weight_i = torch.empty(out_features, in_features).uniform_(-math.sqrt(k), math.sqrt(k))\n",
    "        self.weight_i = nn.Parameter(weight_i)\n",
    "        weight_q = torch.empty(out_features, in_features).uniform_(-math.sqrt(k), math.sqrt(k))\n",
    "        self.weight_q = nn.Parameter(weight_q)\n",
    "        \n",
    "        bias_i = torch.empty(out_features).uniform_(-k, k)\n",
    "        self.bias_i = nn.Parameter(bias_i)\n",
    "        bias_q = torch.empty(out_features).uniform_(-k, k)\n",
    "        self.bias_q = nn.Parameter(bias_q)\n",
    "        \n",
    "    def forward(self, x_i, x_q):\n",
    "        i = nn.functional.linear(x_i, self.weight_i, self.bias_i)\n",
    "        q = nn.functional.linear(x_q, self.weight_q, self.bias_q)\n",
    "        return i - q, i + q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexANN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_neuron):\n",
    "        super().__init__()\n",
    "        self.fc1 = ComplexLinear(input_dim, hidden_neuron)\n",
    "        self.fc2 = ComplexLinear(hidden_neuron, output_dim)\n",
    "    \n",
    "    def forward(self, x_i, x_q):\n",
    "        x_i, x_q = self.fc1(x_i, x_q)\n",
    "        x_i, x_q = zrelu(x_i, x_q)\n",
    "        x_i, x_q = self.fc2(x_i, x_q)\n",
    "        return x_i, x_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available now: cpu\n",
      "(tensor([[-0.3372],\n",
      "        [ 0.0065],\n",
      "        [-0.1188],\n",
      "        [-0.2284],\n",
      "        [ 0.4132],\n",
      "        [ 0.0963],\n",
      "        [-0.0059],\n",
      "        [-0.1239],\n",
      "        [ 0.0098],\n",
      "        [-0.1476],\n",
      "        [-0.0279],\n",
      "        [-0.0378],\n",
      "        [-0.4654],\n",
      "        [-0.0523],\n",
      "        [-0.1903],\n",
      "        [ 0.3583],\n",
      "        [ 0.2229],\n",
      "        [ 0.9096],\n",
      "        [ 0.2470],\n",
      "        [ 0.1467],\n",
      "        [-0.4539],\n",
      "        [ 0.0122],\n",
      "        [-0.5994],\n",
      "        [-0.2310],\n",
      "        [-0.0688],\n",
      "        [-0.0482],\n",
      "        [-0.0548],\n",
      "        [ 0.2929],\n",
      "        [ 0.0272],\n",
      "        [-0.0711],\n",
      "        [ 0.0931],\n",
      "        [-0.1775],\n",
      "        [-0.0110],\n",
      "        [-0.3034],\n",
      "        [-0.3861],\n",
      "        [-0.2332],\n",
      "        [-0.2973],\n",
      "        [-0.0652],\n",
      "        [-0.3847],\n",
      "        [-0.1630],\n",
      "        [-0.1719],\n",
      "        [-0.0063],\n",
      "        [ 0.1056],\n",
      "        [ 0.0706],\n",
      "        [-0.3275],\n",
      "        [-0.2590],\n",
      "        [-0.4005],\n",
      "        [ 0.2107],\n",
      "        [ 0.4316],\n",
      "        [-0.3753],\n",
      "        [ 0.0258],\n",
      "        [ 0.0821],\n",
      "        [ 0.2743],\n",
      "        [-0.3432],\n",
      "        [-0.1609],\n",
      "        [ 0.1522],\n",
      "        [-0.4874],\n",
      "        [-0.2264],\n",
      "        [ 0.5163],\n",
      "        [ 0.4537],\n",
      "        [ 0.0955],\n",
      "        [-0.1163],\n",
      "        [-0.3296],\n",
      "        [ 0.3211],\n",
      "        [ 0.4393],\n",
      "        [-0.3308],\n",
      "        [-0.4664],\n",
      "        [ 0.4022],\n",
      "        [ 0.1742],\n",
      "        [-0.0187],\n",
      "        [ 0.1473],\n",
      "        [ 0.0181],\n",
      "        [-0.1287],\n",
      "        [ 0.0085],\n",
      "        [ 0.0372],\n",
      "        [-0.1748],\n",
      "        [ 0.1202],\n",
      "        [ 0.0948],\n",
      "        [-0.4066],\n",
      "        [ 0.1071],\n",
      "        [ 0.4233],\n",
      "        [-0.1087],\n",
      "        [-0.4583],\n",
      "        [-0.1667],\n",
      "        [ 0.3169],\n",
      "        [-0.3214],\n",
      "        [ 0.2272],\n",
      "        [-0.0300],\n",
      "        [-0.1104],\n",
      "        [-0.4490],\n",
      "        [ 0.1105],\n",
      "        [ 0.0630],\n",
      "        [ 0.2617],\n",
      "        [-0.1396],\n",
      "        [ 0.2248],\n",
      "        [ 0.1074],\n",
      "        [ 0.3344],\n",
      "        [-0.1459],\n",
      "        [ 0.1184],\n",
      "        [-0.3797]], grad_fn=<SubBackward0>), tensor([[ 0.1827],\n",
      "        [-0.1176],\n",
      "        [ 0.2390],\n",
      "        [ 0.0956],\n",
      "        [-0.2637],\n",
      "        [ 0.1470],\n",
      "        [ 0.3145],\n",
      "        [-0.0713],\n",
      "        [ 0.5043],\n",
      "        [-0.1469],\n",
      "        [ 0.1776],\n",
      "        [-0.1746],\n",
      "        [-0.6235],\n",
      "        [-0.1587],\n",
      "        [-0.3276],\n",
      "        [ 0.1116],\n",
      "        [-0.0739],\n",
      "        [-0.5444],\n",
      "        [ 0.4725],\n",
      "        [-0.6130],\n",
      "        [-0.2133],\n",
      "        [-0.4349],\n",
      "        [-0.0330],\n",
      "        [-0.5501],\n",
      "        [-0.4733],\n",
      "        [ 0.0948],\n",
      "        [ 0.0325],\n",
      "        [-0.2950],\n",
      "        [-0.8412],\n",
      "        [-0.3145],\n",
      "        [-0.0133],\n",
      "        [-0.3534],\n",
      "        [ 0.1445],\n",
      "        [ 0.0781],\n",
      "        [-0.4154],\n",
      "        [-0.6234],\n",
      "        [-0.3476],\n",
      "        [-0.4579],\n",
      "        [-0.0424],\n",
      "        [ 0.2575],\n",
      "        [ 0.3146],\n",
      "        [-0.3589],\n",
      "        [-0.3275],\n",
      "        [-0.0997],\n",
      "        [ 0.1482],\n",
      "        [-0.5409],\n",
      "        [-0.4845],\n",
      "        [-0.3292],\n",
      "        [-0.4451],\n",
      "        [-0.0582],\n",
      "        [-0.1793],\n",
      "        [ 0.0176],\n",
      "        [ 0.3818],\n",
      "        [-0.0208],\n",
      "        [-0.3319],\n",
      "        [-0.0337],\n",
      "        [-0.4724],\n",
      "        [-0.0318],\n",
      "        [-0.4755],\n",
      "        [-0.2028],\n",
      "        [-0.4365],\n",
      "        [ 0.7512],\n",
      "        [-0.0013],\n",
      "        [-0.2764],\n",
      "        [-0.2204],\n",
      "        [ 0.5626],\n",
      "        [ 0.2635],\n",
      "        [-0.2896],\n",
      "        [-0.0511],\n",
      "        [-0.1061],\n",
      "        [-0.0227],\n",
      "        [-0.0891],\n",
      "        [-0.1717],\n",
      "        [ 0.1502],\n",
      "        [-0.3001],\n",
      "        [-0.3201],\n",
      "        [-0.0829],\n",
      "        [-0.2135],\n",
      "        [ 0.2199],\n",
      "        [-0.2690],\n",
      "        [ 0.1104],\n",
      "        [-0.1580],\n",
      "        [ 0.0432],\n",
      "        [-0.4833],\n",
      "        [-0.0594],\n",
      "        [-0.3300],\n",
      "        [ 0.4761],\n",
      "        [-0.1863],\n",
      "        [-0.3644],\n",
      "        [ 0.1092],\n",
      "        [-0.3434],\n",
      "        [-0.2017],\n",
      "        [ 0.0799],\n",
      "        [ 0.1632],\n",
      "        [-0.0896],\n",
      "        [-0.1360],\n",
      "        [-0.1033],\n",
      "        [-0.4986],\n",
      "        [ 0.1676],\n",
      "        [-0.6009]], grad_fn=<AddBackward0>))\n",
      "torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "#動作確認\n",
    "hidden_neuron = 300\n",
    "device = torch.device('cpu') # 'cuda' if torch.cuda.is_available() else \n",
    "print('Device available now:', device)\n",
    "\n",
    "model = ComplexANN(input_dim=tap, output_dim=1, hidden_neuron=hidden_neuron).to(device)\n",
    "for x_i, x_q, y_i, y_q in train_dataloader:\n",
    "    out_i, out_q = model(x_i, x_q)\n",
    "    print(output)\n",
    "    print(out_i.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. train定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evm_score(x_i, x_q, y_i, y_q):\n",
    "    tmp = 0\n",
    "    for i in range(len(x_i)):\n",
    "        tmp += ((x_i[i] - y_i[i]) ** 2 + (x_q[i] - y_q[i]) ** 2) / (y_i[i] ** 2 + y_q[i] ** 2)\n",
    "    evm = torch.sqrt(tmp / len(x_i))\n",
    "    return evm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(device, model, dataloaders_dict, criterion, optimizer, epochs, epochs_section=None):\n",
    "    for epoch in range(epochs):\n",
    "        if epochs_section is not None:\n",
    "            epoch += epochs_section[0]\n",
    "            end_epoch = epochs_section[1]\n",
    "        else:\n",
    "            end_epoch = epochs\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for phase in dataloaders_dict.keys():\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            epoch_loss = 0.0\n",
    "            epoch_evms = 0.0\n",
    "            \n",
    "            for x_i, x_q, y_i, y_q in dataloaders_dict[phase]:\n",
    "                x_i, x_q = x_i.to(device), x_q.to(device)\n",
    "                y_i, y_q = y_i.to(device), y_q.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    out_i, out_q = model(x_i, x_q)\n",
    "                    loss = evm_score(out_i, out_q, y_i, y_q)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                    epoch_loss += loss.item() * x_i.size(0)\n",
    "                    epoch_evms += (evm_score(out_i, out_q, y_i, y_q)) ** 2 * x_i.size(0)\n",
    "            \n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_evm = torch.sqrt(epoch_evms / len(dataloaders_dict[phase].dataset)) * 100\n",
    "            \n",
    "            duration = str(datetime.timedelta(seconds=time.time() - start_time))[:7]\n",
    "            print('{} | Epoch: {}/{} | {} Loss: {:.4} | EVM: {:.4}'.format(duration, epoch + 1, end_epoch, phase, epoch_loss, epoch_evm[0]))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:00 | Epoch: 1/5 | train Loss: 0.5969 | EVM: 59.72\n",
      "0:01:02 | Epoch: 2/5 | train Loss: 0.5364 | EVM: 53.69\n",
      "0:01:14 | Epoch: 3/5 | train Loss: 0.483 | EVM: 48.34\n",
      "0:01:21 | Epoch: 4/5 | train Loss: 0.4286 | EVM: 42.9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-156-5591af25e5ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataloaders_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-155-47a7eb28dead>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(device, model, dataloaders_dict, criterion, optimizer, epochs, epochs_section)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                     \u001b[0mout_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevm_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pycharmprojects\\masterthesis\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-118-57e2ffd4e57c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x_i, x_q)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_q\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-136-d5383579d705>\u001b[0m in \u001b[0;36mzrelu\u001b[1;34m(x_i, x_q)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mx_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mx_q\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m                 \u001b[0mx_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                 \u001b[0mx_q\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pycharmprojects\\masterthesis\\venv\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#動作確認\n",
    "epochs = 5\n",
    "lr = 0.001\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "train_model(device=device, model=model, dataloaders_dict=dataloaders_dict, criterion=criterion, optimizer=optimizer, epochs=epochs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available now: cpu\n",
      "0:00:58 | Epoch: 1/500 | train Loss: 1.038 | EVM: 103.8\n",
      "0:05:59 | Epoch: 1/500 | val Loss: 1.008 | EVM: 100.8\n",
      "0:01:08 | Epoch: 2/500 | train Loss: 0.7809 | EVM: 78.14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-157-d88e02451549>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataloaders_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-155-47a7eb28dead>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(device, model, dataloaders_dict, criterion, optimizer, epochs, epochs_section)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                     \u001b[0mout_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevm_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pycharmprojects\\masterthesis\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-118-57e2ffd4e57c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x_i, x_q)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_q\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-136-d5383579d705>\u001b[0m in \u001b[0;36mzrelu\u001b[1;34m(x_i, x_q)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mx_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mx_q\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m                 \u001b[0mx_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                 \u001b[0mx_q\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pycharmprojects\\masterthesis\\venv\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#結果を保存しない\n",
    "tap = 201\n",
    "max_tap = 501\n",
    "batch_size = 100\n",
    "hidden_neuron = 300\n",
    "epochs = 500\n",
    "lr = 0.001\n",
    "\n",
    "device = torch.device('cpu') # 'cuda' if torch.cuda.is_available() else \n",
    "print('Device available now:', device)\n",
    "\n",
    "df_dir = '../data/input/'\n",
    "df0 = pd.read_csv(df_dir+'prbs.csv', index_col=0)\n",
    "\n",
    "condition0 = (df0['N']==13) & (df0['itr']==1) & (df0['form']=='RZ16QAM') & (df0['n']==32) & (df0['equalize']==False) & (df0['baudrate']==28) & (df0['PdBm']==1)\n",
    "sgnl0 = load_pickle(df0[condition0].iloc[0]['data_path'])\n",
    "lc0 = sgnl0.linear_compensation(2500, sgnl0.signal['x_2500'])\n",
    "x0, y0 = data_shaping(sgnl0.signal['x_0'][16::32], lc0[16::32], max_tap, tap)\n",
    "\n",
    "condition1 = (df0['N']==17) & (df0['itr']==1) & (df0['form']=='RZ16QAM') & (df0['n']==32) & (df0['equalize']==False) & (df0['baudrate']==28) & (df0['PdBm']==1)\n",
    "sgnl1 = load_pickle(df0[condition1].iloc[0]['data_path'])\n",
    "lc1 = sgnl1.linear_compensation(2500, sgnl1.signal['x_2500'])\n",
    "x1, y1 = data_shaping(sgnl1.signal['x_0'][16::32], lc1[16::32], max_tap, tap)\n",
    "\n",
    "mean = np.mean(x0)\n",
    "std = np.std(x0)\n",
    "\n",
    "train_dataset = Dataset(x=x0, y=y0, mean=mean, std=std)\n",
    "val_dataset = Dataset(x=x1, y=y1, mean=mean, std=std)\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "dataloaders_dict = {'train': train_dataloader, 'val': val_dataloader}\n",
    "\n",
    "model = ComplexANN(input_dim=tap, output_dim=1, hidden_neuron=hidden_neuron).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "model = train_model(device=device, model=model, dataloaders_dict=dataloaders_dict, criterion=criterion, optimizer=optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
